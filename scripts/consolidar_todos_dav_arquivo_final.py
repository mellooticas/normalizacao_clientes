#!/usr/bin/env python3
"""
Script para consolidar TODOS os arquivos de lista DAV em um Ãºnico arquivo
Criando: data/originais/controles_gerais/lista_dav/csv/arquivo_final.csv
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os
import glob
import warnings
warnings.filterwarnings('ignore')

def consolidar_todos_dav():
    """
    Consolida todos os arquivos DAV em um Ãºnico arquivo final
    """
    print("ğŸ“ === CONSOLIDAÃ‡ÃƒO COMPLETA DOS ARQUIVOS DAV === ğŸ“")
    
    # 1. Localizar todos os arquivos CSV da lista DAV
    print("\nğŸ” === LOCALIZANDO ARQUIVOS === ğŸ”")
    
    pasta_dav = 'data/originais/controles_gerais/lista_dav'
    pattern = os.path.join(pasta_dav, '*.csv')
    arquivos = glob.glob(pattern)
    
    print(f"âœ… Encontrados: {len(arquivos)} arquivos CSV")
    
    if len(arquivos) == 0:
        print("âŒ Nenhum arquivo CSV encontrado na pasta lista_dav")
        return False
    
    # Mostrar alguns arquivos encontrados
    print("ğŸ“„ Primeiros arquivos:")
    for i, arquivo in enumerate(sorted(arquivos)[:10]):
        nome = os.path.basename(arquivo)
        print(f"   {i+1:2d}. {nome}")
    
    if len(arquivos) > 10:
        print(f"   ... e mais {len(arquivos)-10} arquivos")
    
    # 2. Processar cada arquivo
    print(f"\nğŸ“Š === PROCESSANDO {len(arquivos)} ARQUIVOS === ğŸ“Š")
    
    todos_dados = []
    arquivos_processados = 0
    total_registros = 0
    erros = []
    
    for arquivo in sorted(arquivos):
        nome_arquivo = os.path.basename(arquivo)
        
        try:
            # Ler arquivo
            df = pd.read_csv(arquivo, encoding='utf-8')
            
            # Adicionar coluna com nome do arquivo de origem
            df['arquivo_origem'] = nome_arquivo
            
            # Contar registros
            registros_arquivo = len(df)
            total_registros += registros_arquivo
            
            # Adicionar aos dados consolidados
            todos_dados.append(df)
            arquivos_processados += 1
            
            print(f"âœ… {nome_arquivo}: {registros_arquivo:,} registros")
            
        except Exception as e:
            erro_msg = f"âŒ {nome_arquivo}: {str(e)}"
            print(erro_msg)
            erros.append(erro_msg)
            continue
    
    # 3. Consolidar todos os dados
    print(f"\nğŸ”— === CONSOLIDANDO DADOS === ğŸ”—")
    
    if len(todos_dados) == 0:
        print("âŒ Nenhum arquivo foi processado com sucesso")
        return False
    
    # Unir todos os DataFrames
    df_consolidado = pd.concat(todos_dados, ignore_index=True, sort=False)
    
    print(f"âœ… Arquivos processados: {arquivos_processados}/{len(arquivos)}")
    print(f"âœ… Total de registros: {len(df_consolidado):,}")
    print(f"âœ… Colunas Ãºnicas: {df_consolidado.shape[1]}")
    
    # 4. AnÃ¡lise dos dados consolidados
    print(f"\nğŸ“Š === ANÃLISE DOS DADOS CONSOLIDADOS === ğŸ“Š")
    
    # Colunas disponÃ­veis
    print(f"ğŸ“‹ Colunas: {', '.join(df_consolidado.columns[:10])}...")
    
    # Arquivos de origem
    origem_dist = df_consolidado['arquivo_origem'].value_counts()
    print(f"ğŸ“„ Arquivos com mais registros:")
    for arquivo, qtd in origem_dist.head(5).items():
        print(f"   {arquivo}: {qtd:,} registros")
    
    # PerÃ­odo (se houver coluna de data)
    colunas_data = [col for col in df_consolidado.columns if any(palavra in col.lower() for palavra in ['data', 'dt', 'dh'])]
    if colunas_data:
        print(f"ğŸ“… Colunas de data encontradas: {', '.join(colunas_data)}")
        
        # Tentar analisar perÃ­odo
        for col_data in colunas_data[:2]:  # Primeiras 2 colunas de data
            try:
                df_consolidado[f'{col_data}_dt'] = pd.to_datetime(df_consolidado[col_data], errors='coerce')
                datas_validas = df_consolidado[f'{col_data}_dt'].dropna()
                
                if len(datas_validas) > 0:
                    inicio = datas_validas.min().strftime('%Y-%m-%d')
                    fim = datas_validas.max().strftime('%Y-%m-%d')
                    print(f"ğŸ“… {col_data}: {inicio} â†’ {fim} ({len(datas_validas):,} registros vÃ¡lidos)")
                    break  # Usar apenas a primeira coluna de data vÃ¡lida
            except:
                continue
    
    # Campos principais (se existirem)
    campos_principais = ['OS', 'Cliente', 'Vendedor', 'Status', 'Dt.entrega']
    campos_encontrados = [campo for campo in campos_principais if campo in df_consolidado.columns]
    
    if campos_encontrados:
        print(f"ğŸ¯ Campos principais encontrados: {', '.join(campos_encontrados)}")
        
        # AnÃ¡lise de cada campo
        for campo in campos_encontrados:
            valores_unicos = df_consolidado[campo].nunique()
            valores_nao_nulos = df_consolidado[campo].notna().sum()
            print(f"   {campo}: {valores_unicos:,} Ãºnicos, {valores_nao_nulos:,} nÃ£o-nulos")
    
    # 5. Salvar arquivo consolidado
    print(f"\nğŸ’¾ === SALVANDO ARQUIVO FINAL === ğŸ’¾")
    
    # Criar diretÃ³rio se nÃ£o existir
    pasta_destino = 'data/originais/controles_gerais/lista_dav/csv'
    os.makedirs(pasta_destino, exist_ok=True)
    
    # Nome do arquivo final
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    arquivo_final = os.path.join(pasta_destino, 'arquivo_final.csv')
    arquivo_final_com_timestamp = os.path.join(pasta_destino, f'arquivo_final_backup_{timestamp}.csv')
    
    # Salvar arquivo principal
    df_consolidado.to_csv(arquivo_final, index=False, encoding='utf-8')
    print(f"âœ… Arquivo principal: {arquivo_final}")
    
    # Salvar backup com timestamp
    df_consolidado.to_csv(arquivo_final_com_timestamp, index=False, encoding='utf-8')
    print(f"âœ… Backup: {arquivo_final_com_timestamp}")
    
    # 6. RelatÃ³rio final
    print(f"\nğŸ“‹ === RELATÃ“RIO FINAL === ğŸ“‹")
    print(f"ğŸ“Š Registros totais: {len(df_consolidado):,}")
    print(f"ğŸ“„ Arquivos processados: {arquivos_processados}/{len(arquivos)}")
    print(f"ğŸ“‹ Colunas: {df_consolidado.shape[1]}")
    print(f"ğŸ’¾ Arquivo gerado: {arquivo_final}")
    print(f"ğŸ“ Tamanho aproximado: {len(df_consolidado) * df_consolidado.shape[1] * 50 / 1024 / 1024:.1f} MB")
    
    # Mostrar erros se houver
    if erros:
        print(f"\nâš ï¸ === ERROS ENCONTRADOS === âš ï¸")
        for erro in erros:
            print(f"   {erro}")
    
    return arquivo_final

def verificar_arquivo_gerado(arquivo):
    """
    Verifica o arquivo gerado
    """
    if not os.path.exists(arquivo):
        print(f"âŒ Arquivo nÃ£o encontrado: {arquivo}")
        return False
    
    print(f"\nâœ… === VERIFICAÃ‡ÃƒO DO ARQUIVO === âœ…")
    
    # InformaÃ§Ãµes do arquivo
    tamanho = os.path.getsize(arquivo) / 1024 / 1024
    print(f"ğŸ“„ Arquivo: {arquivo}")
    print(f"ğŸ’¾ Tamanho: {tamanho:.1f} MB")
    
    # Ler primeiras linhas
    try:
        df_teste = pd.read_csv(arquivo, nrows=5)
        print(f"ğŸ“Š Linhas de teste: {len(df_teste)}")
        print(f"ğŸ“‹ Colunas: {df_teste.shape[1]}")
        print(f"ğŸ“‹ Primeiras colunas: {', '.join(df_teste.columns[:10])}")
        
        # Contar total de linhas
        with open(arquivo, 'r', encoding='utf-8') as f:
            linhas = sum(1 for _ in f) - 1  # -1 para o cabeÃ§alho
        print(f"ğŸ“Š Total de linhas de dados: {linhas:,}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro verificando arquivo: {e}")
        return False

def main():
    """FunÃ§Ã£o principal"""
    print("ğŸ¯ === CONSOLIDAÃ‡ÃƒO COMPLETA LISTA DAV === ğŸ¯")
    print("ğŸ“ Origem: data/originais/controles_gerais/lista_dav/*.csv")
    print("ğŸ“ Destino: data/originais/controles_gerais/lista_dav/csv/arquivo_final.csv")
    
    arquivo_final = consolidar_todos_dav()
    
    if arquivo_final:
        print(f"\nğŸ‰ === CONSOLIDAÃ‡ÃƒO CONCLUÃDA === ğŸ‰")
        
        # Verificar arquivo gerado
        if verificar_arquivo_gerado(arquivo_final):
            print(f"âœ… Arquivo consolidado disponÃ­vel em: {arquivo_final}")
            print(f"ğŸ”— Todos os arquivos DAV agora estÃ£o em um Ãºnico arquivo!")
            print(f"ğŸ“… Processado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        else:
            print(f"âš ï¸ Arquivo gerado, mas com problemas na verificaÃ§Ã£o")
    else:
        print(f"\nâŒ === FALHA NA CONSOLIDAÃ‡ÃƒO === âŒ")
        print("Verifique os logs acima para detalhes")

if __name__ == "__main__":
    main()