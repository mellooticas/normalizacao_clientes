#!/usr/bin/env python3
"""
Script para preparar os 2.247 cruzamentos DAV para a estrutura REAL da tabela entregas_os
Estrutura: id, venda_id, vendedor_id, data_entrega, tem_carne, created_at, updated_at, deleted_at
"""

import pandas as pd
import numpy as np
from datetime import datetime
import uuid
import warnings
warnings.filterwarnings('ignore')

def gerar_uuid():
    """Gera UUID Ãºnico"""
    return str(uuid.uuid4())

def preparar_cruzamentos_para_supabase():
    """
    Prepara os 2.247 cruzamentos para a estrutura real da tabela entregas_os
    """
    print("ðŸŽ¯ === PREPARANDO CRUZAMENTOS PARA SUPABASE === ðŸŽ¯")
    print("ðŸ“‹ Estrutura: id, venda_id, vendedor_id, data_entrega, tem_carne")
    
    # 1. Carregar cruzamentos
    print("\nðŸ“Š === CARREGANDO CRUZAMENTOS === ðŸ“Š")
    
    arquivo_cruzamentos = 'data/cruzamentos_completos_dav_vendas_20251105_032132.csv'
    df = pd.read_csv(arquivo_cruzamentos)
    print(f"âœ… Cruzamentos carregados: {len(df):,}")
    
    # AnÃ¡lise por tipo
    tipo_dist = df['tipo_match'].value_counts()
    print(f"ðŸ“Š Por tipo:")
    for tipo, qtd in tipo_dist.items():
        print(f"   {tipo}: {qtd:,}")
    
    # 2. Filtrar cruzamentos vÃ¡lidos
    print("\nðŸ” === FILTRANDO CRUZAMENTOS VÃLIDOS === ðŸ”")
    
    # Filtros obrigatÃ³rios
    df_valido = df.dropna(subset=['venda_id', 'data_entrega'])
    print(f"ðŸ“Š Com venda_id e data_entrega: {len(df_valido):,}")
    
    # Converter datas
    df_valido['data_entrega_dt'] = pd.to_datetime(df_valido['data_entrega'], format='%d/%m/%Y', errors='coerce')
    df_valido['data_venda_dt'] = pd.to_datetime(df_valido['data_venda'], errors='coerce')
    
    # Filtrar datas vÃ¡lidas
    df_valido = df_valido.dropna(subset=['data_entrega_dt'])
    print(f"ðŸ“Š Com datas vÃ¡lidas: {len(df_valido):,}")
    
    # Filtrar lÃ³gica de datas (entrega deve ser apÃ³s venda, atÃ© 2 anos)
    df_valido['dias_diferenca'] = (df_valido['data_entrega_dt'] - df_valido['data_venda_dt']).dt.days
    df_logico = df_valido[(df_valido['dias_diferenca'] >= -30) & (df_valido['dias_diferenca'] <= 730)]  # -30 a +730 dias
    print(f"ðŸ“Š Com lÃ³gica temporal vÃ¡lida: {len(df_logico):,}")
    
    # 3. Remover duplicatas por venda_id + data_entrega (constraint Ãºnica)
    print("\nðŸ”„ === REMOVENDO DUPLICATAS === ðŸ”„")
    
    antes = len(df_logico)
    df_unico = df_logico.drop_duplicates(subset=['venda_id', 'data_entrega_dt'])
    depois = len(df_unico)
    print(f"ðŸ“Š Antes: {antes:,} | Depois: {depois:,} | Removidas: {antes-depois:,}")
    
    # 4. Preparar dados para Supabase (estrutura real)
    print("\nðŸ”§ === PREPARANDO ESTRUTURA SUPABASE === ðŸ”§")
    
    entregas_supabase = []
    
    for _, row in df_unico.iterrows():
        try:
            # Determinar tem_carne baseado na descriÃ§Ã£o
            descricao = str(row.get('cliente_nome_dav', '')).upper()
            arquivo_origem = str(row.get('arquivo_origem', '')).upper()
            
            # LÃ³gica para detectar lentes de contato (tem_carne = true)
            tem_carne = any(palavra in descricao + ' ' + arquivo_origem for palavra in [
                'LENTE', 'CONTATO', 'LC', 'ACUVUE', 'BIOFINITY', 'PROCLEAR',
                'COOPERVISION', 'BAUSCH', 'JOHNSON', 'ALCON'
            ])
            
            # Preparar registro para Supabase (ESTRUTURA REAL)
            entrega = {
                'id': gerar_uuid(),
                'venda_id': row['venda_id'],
                'vendedor_id': row.get('vendedor_id_venda') if pd.notna(row.get('vendedor_id_venda')) else None,
                'data_entrega': row['data_entrega_dt'].strftime('%Y-%m-%d'),
                'tem_carne': tem_carne,
                'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'deleted_at': None
            }
            
            entregas_supabase.append(entrega)
            
        except Exception as e:
            print(f"âš ï¸ Erro processando linha: {e}")
            continue
    
    # 5. Criar DataFrame final
    df_final = pd.DataFrame(entregas_supabase)
    print(f"ðŸ“¦ Entregas preparadas: {len(df_final):,}")
    
    # 6. AnÃ¡lise dos dados preparados
    print(f"\nðŸ“Š === ANÃLISE DOS DADOS PREPARADOS === ðŸ“Š")
    
    # AnÃ¡lise tem_carne
    carne_dist = df_final['tem_carne'].value_counts()
    print(f"ðŸ¥© Com carne (lentes): {carne_dist.get(True, 0):,}")
    print(f"ðŸ‘“ Sem carne (Ã³culos): {carne_dist.get(False, 0):,}")
    
    # PerÃ­odo
    df_final['data_entrega_dt'] = pd.to_datetime(df_final['data_entrega'])
    periodo = f"{df_final['data_entrega_dt'].min().strftime('%Y-%m-%d')} â†’ {df_final['data_entrega_dt'].max().strftime('%Y-%m-%d')}"
    print(f"ðŸ“… PerÃ­odo: {periodo}")
    
    # Vendedores
    vendedores_validos = df_final['vendedor_id'].dropna()
    print(f"ðŸ‘¤ Vendedores vÃ¡lidos: {len(vendedores_validos):,} de {len(df_final):,} ({len(vendedores_validos)/len(df_final)*100:.1f}%)")
    print(f"ðŸ‘¤ Vendedores Ãºnicos: {vendedores_validos.nunique():,}")
    
    # Vendas Ãºnicas
    print(f"ðŸ›’ Vendas Ãºnicas: {df_final['venda_id'].nunique():,}")
    
    # 7. AnÃ¡lise por tipo de match original
    print(f"\nðŸ“Š === ANÃLISE POR TIPO DE MATCH === ðŸ“Š")
    
    # Merge com dados originais para ver tipos
    df_final_com_tipo = df_final.merge(
        df_unico[['venda_id', 'data_entrega_dt', 'tipo_match', 'cliente_nome_dav', 'loja_dav']], 
        on=['venda_id'], 
        suffixes=('', '_orig'),
        how='left'
    )
    
    # Filtrar por data prÃ³xima (para casos de mÃºltiplas datas)
    df_final_com_tipo['diff_days'] = abs((df_final_com_tipo['data_entrega_dt'] - df_final_com_tipo['data_entrega_dt_orig']).dt.days)
    df_final_com_tipo = df_final_com_tipo.sort_values('diff_days').drop_duplicates(subset=['venda_id', 'data_entrega_dt'])
    
    if 'tipo_match' in df_final_com_tipo.columns:
        tipo_final = df_final_com_tipo['tipo_match'].value_counts()
        print(f"ðŸ“Š Por origem do match:")
        for tipo, qtd in tipo_final.items():
            print(f"   {tipo}: {qtd:,}")
    
    # Por loja
    if 'loja_dav' in df_final_com_tipo.columns:
        loja_final = df_final_com_tipo['loja_dav'].value_counts()
        print(f"ðŸª Por loja:")
        for loja, qtd in loja_final.items():
            print(f"   {loja}: {qtd:,}")
    
    # 8. Salvar arquivo CSV (apenas colunas necessÃ¡rias)
    print(f"\nðŸ’¾ === SALVANDO ARQUIVO === ðŸ’¾")
    
    # Selecionar apenas colunas da tabela real
    colunas_tabela = ['id', 'venda_id', 'vendedor_id', 'data_entrega', 'tem_carne', 'created_at', 'updated_at', 'deleted_at']
    df_export = df_final[colunas_tabela].copy()
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    arquivo_csv = f"data/entregas_supabase_2247_cruzamentos_{timestamp}.csv"
    
    df_export.to_csv(arquivo_csv, index=False)
    
    print(f"ðŸ“„ Arquivo: {arquivo_csv}")
    print(f"ðŸ“Š Registros: {len(df_export):,}")
    print(f"ðŸ“‹ Colunas: {', '.join(df_export.columns)}")
    
    # 9. VerificaÃ§Ã£o final
    print(f"\nðŸ” === VERIFICAÃ‡ÃƒO FINAL === ðŸ”")
    
    # Verificar se hÃ¡ valores nulos onde nÃ£o deveria
    venda_id_nulos = df_export['venda_id'].isnull().sum()
    data_entrega_nulos = df_export['data_entrega'].isnull().sum()
    
    print(f"âœ… venda_id nulos: {venda_id_nulos} (deve ser 0)")
    print(f"âœ… data_entrega nulos: {data_entrega_nulos} (deve ser 0)")
    
    # Verificar constraint Ãºnica
    duplicatas = df_export.duplicated(subset=['venda_id', 'data_entrega']).sum()
    print(f"âœ… Duplicatas venda_id+data_entrega: {duplicatas} (deve ser 0)")
    
    # Verificar UUIDs vÃ¡lidos
    uuids_validos = df_export['venda_id'].str.len().eq(36).all()
    print(f"âœ… UUIDs venda_id vÃ¡lidos: {uuids_validos}")
    
    # 10. InstruÃ§Ãµes de importaÃ§Ã£o
    print(f"\nðŸ“‹ === INSTRUÃ‡Ã•ES PARA IMPORTAÃ‡ÃƒO === ðŸ“‹")
    print(f"1. Acesse o Supabase: https://zlcgursmvxqcalimvjxl.supabase.co")
    print(f"2. VÃ¡ para Table Editor â†’ entregas_os")
    print(f"3. Clique em 'Insert' â†’ 'Import data from CSV'")
    print(f"4. Selecione o arquivo: {arquivo_csv}")
    print(f"5. Mapeie as colunas:")
    print(f"   - id â†’ id (UUID)")
    print(f"   - venda_id â†’ venda_id (UUID)")
    print(f"   - vendedor_id â†’ vendedor_id (UUID)")
    print(f"   - data_entrega â†’ data_entrega (DATE)")
    print(f"   - tem_carne â†’ tem_carne (BOOLEAN)")
    print(f"   - created_at â†’ created_at (TIMESTAMP)")
    print(f"   - updated_at â†’ updated_at (TIMESTAMP)")
    print(f"   - deleted_at â†’ deleted_at (TIMESTAMP)")
    print(f"6. Execute a importaÃ§Ã£o de {len(df_export):,} registros")
    
    return arquivo_csv

def main():
    """FunÃ§Ã£o principal"""
    print("ðŸŽ¯ === PREPARAÃ‡ÃƒO DOS 2.247 CRUZAMENTOS === ðŸŽ¯")
    print("ðŸ“‹ Para estrutura real da tabela entregas_os")
    
    arquivo = preparar_cruzamentos_para_supabase()
    
    if arquivo:
        print(f"\nðŸŽ‰ === PREPARAÃ‡ÃƒO CONCLUÃDA === ðŸŽ‰")
        print(f"âœ… Arquivo CSV pronto para importaÃ§Ã£o")
        print(f"ðŸ“„ {arquivo}")
        print(f"ðŸšš Entregas dos cruzamentos DAV preparadas!")
        print(f"ðŸŽ¯ Estrutura 100% compatÃ­vel com tabela entregas_os")
        print(f"ðŸ“… Processado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        print(f"\nâŒ === ERRO NA PREPARAÃ‡ÃƒO === âŒ")

if __name__ == "__main__":
    main()