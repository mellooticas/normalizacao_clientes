#!/usr/bin/env python3
"""
AnÃ¡lise detalhada de duplicatas por constraint uq_vendas_loja_numero
Identifica e resolve todas as duplicatas de numero_venda + loja_id
"""

import pandas as pd
from pathlib import Path

def analisar_constraint_loja_numero():
    """Analisa duplicatas especÃ­ficas da constraint uq_vendas_loja_numero"""
    
    base_dir = Path("d:/projetos/carne_facil/carne_facil")
    vendas_dir = base_dir / "data" / "vendas_para_importar"
    
    print("ğŸ” === ANÃLISE CONSTRAINT uq_vendas_loja_numero === ğŸ”")
    print()
    
    # 1. Carrega os 3 arquivos atuais
    print("ğŸ“‚ Carregando arquivos...")
    
    # OSS
    arquivo_oss = vendas_dir / "vendas_PRONTO_PARA_IMPORTAR_97pct_LIMPO.csv"
    oss_df = pd.read_csv(arquivo_oss)
    oss_df['fonte'] = 'OSS'
    print(f"âœ… OSS: {len(oss_df)} vendas")
    
    # VIXEN CarnÃª (limpo)
    arquivo_vixen_carne = vendas_dir / "vendas_VIXEN_CARNE_SEM_DUPLICATAS.csv"
    vixen_carne_df = pd.read_csv(arquivo_vixen_carne)
    vixen_carne_df['fonte'] = 'VIXEN_CARNE'
    print(f"âœ… VIXEN CarnÃª Limpo: {len(vixen_carne_df)} vendas")
    
    # VIXEN Completo
    arquivo_vixen_completo = vendas_dir / "vendas_COMPLETAS_ESTRUTURA_CORRIGIDA.csv"
    vixen_completo_df = pd.read_csv(arquivo_vixen_completo)
    vixen_completo_df['fonte'] = 'VIXEN_COMPLETO'
    print(f"âœ… VIXEN Completo: {len(vixen_completo_df)} vendas")
    
    print()
    
    # 2. Combina todos os arquivos
    print("ğŸ”— Combinando todos os arquivos...")
    todos_df = pd.concat([oss_df, vixen_carne_df, vixen_completo_df], ignore_index=True)
    print(f"ğŸ“Š Total combinado: {len(todos_df)} vendas")
    
    # 3. Cria chave da constraint
    todos_df['chave_constraint'] = todos_df['loja_id'].astype(str) + "_" + todos_df['numero_venda'].astype(str)
    
    # 4. Identifica duplicatas por constraint
    print(f"\nğŸ” Analisando constraint uq_vendas_loja_numero...")
    
    duplicatas_constraint = todos_df[todos_df.duplicated(subset=['chave_constraint'], keep=False)]
    duplicatas_constraint = duplicatas_constraint.sort_values(['loja_id', 'numero_venda', 'fonte'])
    
    total_duplicatas = len(duplicatas_constraint)
    grupos_duplicados = duplicatas_constraint.groupby('chave_constraint').size()
    
    print(f"ğŸ“Š Total de registros duplicados: {total_duplicatas}")
    print(f"ğŸ”¢ Grupos de duplicatas: {len(grupos_duplicados)}")
    print(f"ğŸ“ˆ Registros Ãºnicos que serÃ£o mantidos: {len(grupos_duplicados)}")
    print(f"ğŸ—‘ï¸  Registros que serÃ£o removidos: {total_duplicatas - len(grupos_duplicados)}")
    
    # 5. AnÃ¡lise detalhada das duplicatas
    print(f"\nğŸ“‹ === DETALHAMENTO DAS DUPLICATAS === ğŸ“‹")
    
    if total_duplicatas > 0:
        print(f"Amostra das duplicatas encontradas:")
        for i, (chave, grupo) in enumerate(grupos_duplicados.head(10).items()):
            exemplos = duplicatas_constraint[duplicatas_constraint['chave_constraint'] == chave]
            loja_id = exemplos.iloc[0]['loja_id']
            numero = exemplos.iloc[0]['numero_venda']
            loja_nome = "SUZANO" if "52f92716" in loja_id else "MAUÃ" if "aa7a5646" in loja_id else "OUTRA"
            
            print(f"\n   {i+1}. Loja: {loja_nome} | NÃºmero: {numero} | {grupo} duplicatas")
            for j, row in exemplos.iterrows():
                print(f"      - {row['fonte']}: Cliente {row['cliente_id'][:8]}... | Data: {row['data_venda']} | Valor: R$ {row['valor_total']}")
    
    # 6. AnÃ¡lise por fonte
    print(f"\nğŸ“Š === DUPLICATAS POR FONTE === ğŸ“Š")
    
    if total_duplicatas > 0:
        duplicatas_por_fonte = duplicatas_constraint['fonte'].value_counts()
        print(f"Duplicatas por arquivo:")
        for fonte, count in duplicatas_por_fonte.items():
            print(f"   {fonte}: {count} registros duplicados")
        
        # Verificar quais fontes conflitam
        print(f"\nğŸ”„ Conflitos entre fontes:")
        for chave, grupo in grupos_duplicados.items():
            if grupo > 1:
                fontes_conflito = duplicatas_constraint[duplicatas_constraint['chave_constraint'] == chave]['fonte'].unique()
                if len(fontes_conflito) > 1:
                    numero = duplicatas_constraint[duplicatas_constraint['chave_constraint'] == chave].iloc[0]['numero_venda']
                    loja_id = duplicatas_constraint[duplicatas_constraint['chave_constraint'] == chave].iloc[0]['loja_id']
                    loja_nome = "SUZANO" if "52f92716" in loja_id else "MAUÃ" if "aa7a5646" in loja_id else "OUTRA"
                    print(f"   {loja_nome} {numero}: {list(fontes_conflito)}")
    
    # 7. EstratÃ©gia de resoluÃ§Ã£o
    print(f"\nğŸ’¡ === ESTRATÃ‰GIA DE RESOLUÃ‡ÃƒO === ğŸ’¡")
    
    if total_duplicatas > 0:
        print(f"Prioridades para manter registros:")
        print(f"   1ï¸âƒ£ OSS (dados mais recentes e confiÃ¡veis)")
        print(f"   2ï¸âƒ£ VIXEN_COMPLETO (dataset mais abrangente)")
        print(f"   3ï¸âƒ£ VIXEN_CARNE (subset especÃ­fico)")
        
        # Aplicar estratÃ©gia de prioridade
        print(f"\nğŸ§¹ Aplicando estratÃ©gia de prioridade...")
        
        def prioridade_fonte(fonte):
            if fonte == 'OSS':
                return 1
            elif fonte == 'VIXEN_COMPLETO':
                return 2
            elif fonte == 'VIXEN_CARNE':
                return 3
            else:
                return 4
        
        todos_df['prioridade'] = todos_df['fonte'].apply(prioridade_fonte)
        
        # Remove duplicatas mantendo apenas o de maior prioridade
        todos_limpo = todos_df.sort_values('prioridade').drop_duplicates(
            subset=['chave_constraint'], 
            keep='first'
        )
        
        # Remove colunas temporÃ¡rias
        todos_limpo = todos_limpo.drop(columns=['fonte', 'chave_constraint', 'prioridade'])
        
        print(f"âœ… Registros apÃ³s limpeza: {len(todos_limpo)}")
        print(f"ğŸ—‘ï¸  Registros removidos: {len(todos_df) - len(todos_limpo)}")
        
        # 8. Gera arquivo final unificado
        arquivo_final = vendas_dir / "vendas_UNIFICADO_SEM_DUPLICATAS_CONSTRAINT.csv"
        todos_limpo.to_csv(arquivo_final, index=False)
        
        print(f"\nğŸ’¾ Arquivo final gerado: {arquivo_final}")
        print(f"ğŸ“Š {len(todos_limpo)} vendas prontas para importaÃ§Ã£o")
        
        # 9. EstatÃ­sticas finais
        print(f"\nğŸ“Š === ESTATÃSTICAS FINAIS === ğŸ“Š")
        valor_total = todos_limpo['valor_total'].sum()
        print(f"ğŸ’° Valor total: R$ {valor_total:,.2f}")
        
        por_loja = todos_limpo.groupby('loja_id').agg({
            'valor_total': ['count', 'sum']
        })
        
        for loja_id in todos_limpo['loja_id'].unique():
            subset = todos_limpo[todos_limpo['loja_id'] == loja_id]
            count = len(subset)
            valor = subset['valor_total'].sum()
            loja_nome = "SUZANO" if "52f92716" in loja_id else "MAUÃ" if "aa7a5646" in loja_id else "OUTRAS"
            print(f"   {loja_nome}: {count} vendas (R$ {valor:,.2f})")
        
        return todos_limpo, arquivo_final
    
    else:
        print(f"âœ… Nenhuma duplicata de constraint encontrada!")
        return None, None

if __name__ == "__main__":
    resultado, arquivo = analisar_constraint_loja_numero()
    
    if resultado is not None:
        print(f"\nğŸ¯ SOLUÃ‡ÃƒO PRONTA!")
        print(f"ğŸ“‚ Use apenas o arquivo: {arquivo.name}")
        print(f"ğŸš€ Este arquivo Ãºnico substitui os 3 anteriores!")
    else:
        print(f"\nâœ… Os arquivos atuais estÃ£o prontos para importaÃ§Ã£o!")